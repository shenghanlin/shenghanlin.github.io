<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>CNN vs Transformer | Md Awsafur Rahman</title> <meta name="author" content="Md Awsafur Rahman"> <meta name="description" content="Why use Transformer outperforms CNN??"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/title_icon.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://awsaf49.github.io/blog/2023/cnn-vs-transformer/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Md Awsafur </span>Rahman</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"></a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/awards/">Awards</a> </li> <li class="nav-item "> <a class="nav-link" href="/experience/">Experience</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/repositories/">Repositories</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/personal/">Personal</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">CNN vs Transformer</h1> <p class="post-meta">May 12, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/category/kaggle"> <i class="fas fa-tag fa-sm"></i> kaggle</a>   <a href="/blog/category/cnn"> <i class="fas fa-tag fa-sm"></i> cnn</a>   <a href="/blog/category/transformer"> <i class="fas fa-tag fa-sm"></i> transformer</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="introduction">Introduction</h2> <p>In the <a href="https://www.kaggle.com/competitions/petfinder-pawpularity-score/" rel="external nofollow noopener" target="_blank">PetFinder.my - Pawpularity Contest</a>, participants were challenged to predict which pets were more likely to be adopted based on their images and metadata. Initially, Convolutional Neural Networks (CNNs) showed promising results in this competition. However, as time went on, a new model called Transformer emerged and surpassed CNN by a significant margin. This raises the question: <strong>Why did the Transformer outperform CNN?</strong></p> <h2 id="why">Why??</h2> <p>When it comes to adopting a pet, humans are often drawn to pets that look appealing. However, this appeal is not solely dependent on a cute face; it considers the entire picture, including the tail, fur, surroundings, and more. Similarly, we expect a deep learning model to consider these factors when making predictions. Let’s delve into what CNN and Transformer models focus on in an image before making their decisions.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/cnn_vs_transformer.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/cnn_vs_transformer.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/cnn_vs_transformer.gif-1400.webp"></source> <img src="/assets/img/cnn_vs_transformer.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> GradCAM of CNN vs AttentionMAP of Transformer. </div> <p>From the animation above, we can observe that the CNN model (<code class="language-plaintext highlighter-rouge">EfficientNet</code>) mainly concentrates on the facial features of the image, such as the eyes, nose, and mouth. On the other hand, the Transformer model (<code class="language-plaintext highlighter-rouge">ViT</code>) pays attention to all the features of the image, including the tail, fur, surroundings, and more.</p> <h2 id="how">How??</h2> <p>Now that we understand the “why,” let’s explore the <strong>“How” behind the Transformer’s success and the CNN’s limitations.</strong></p> <h3 id="convolutional-neural-network-cnn">Convolutional Neural Network (CNN)</h3> <p>Code:</p> <ul> <li>train: <a href="https://www.kaggle.com/awsaf49/tf-petfinder-image-tpu-train" rel="external nofollow noopener" target="_blank">PetFinder: CNN [TPU][Train] 🐶</a> </li> <li>infer: <a href="https://www.kaggle.com/awsaf49/tf-petfinder-image-tpu-infer" rel="external nofollow noopener" target="_blank">PetFinder: CNN [TPU][Infer] 🐶</a> </li> </ul> <blockquote> <p>CNNs are limited by their <strong>local receptive field</strong>. During the convolutional process, a CNN can only perceive information within its <code class="language-plaintext highlighter-rouge">kernel_size</code>, which means it lacks the context of regions outside that area—a limitation referred to as “local-context.” Typically, the kernel size in a CNN model is set to <code class="language-plaintext highlighter-rouge">3x3</code> or <code class="language-plaintext highlighter-rouge">5x5</code>. While the receptive field of a CNN expands as the model’s depth increases, thanks to the reduction in resolution, it still remains “short-sighted” due to the limited receptive field.</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="https://149695847.v2.pressablecdn.com/wp-content/uploads/2018/01/conv-full-layer.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="https://149695847.v2.pressablecdn.com/wp-content/uploads/2018/01/conv-full-layer.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://149695847.v2.pressablecdn.com/wp-content/uploads/2018/01/conv-full-layer.gif-1400.webp"></source> <img src="https://149695847.v2.pressablecdn.com/wp-content/uploads/2018/01/conv-full-layer.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Mechanism of CNn </div> <h3 id="transformer">Transformer</h3> <p>Code:</p> <ul> <li>train: <a href="https://www.kaggle.com/awsaf49/tf-petfinder-vit-cls-tpu-train/" rel="external nofollow noopener" target="_blank">PetFinder: Transformer [TPU][Train] 😺</a> </li> <li>infer: <a href="https://www.kaggle.com/awsaf49/tf-petfinder-vit-cls-tpu-infer" rel="external nofollow noopener" target="_blank">PetFinder: Transformer [TPU][Infer] 😺</a> </li> </ul> <blockquote> <p>On the other hand, Transformers possess a superpower known as the <strong>Global Receptive Field</strong>. This allows them to perceive the entire picture when making decisions. Transformers achieve this global awareness through a mechanism called <code class="language-plaintext highlighter-rouge">self-attention</code> which dynamically focuses on relevant information from different parts of the image enabling better understanding of the scene.</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="https://upload.wikimedia.org/wikipedia/commons/3/3e/Vision_Transformer.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="https://upload.wikimedia.org/wikipedia/commons/3/3e/Vision_Transformer.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://upload.wikimedia.org/wikipedia/commons/3/3e/Vision_Transformer.gif-1400.webp"></source> <img src="https://upload.wikimedia.org/wikipedia/commons/3/3e/Vision_Transformer.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Mechanism of Vision Transformer </div> <blockquote class="block-tip"> <p><strong>Summary:</strong> CNNs are limited by their local-context perspective while Transformers can capture the broader context of an image, including the appealing features that contribute to a pet’s adoptability.</p> </blockquote> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/displaying-external-posts-on-your-al-folio-blog/">Displaying External Posts on Your al-folio Blog</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/llm-science/">LLM Science Exam</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/2.5d-training/">2.5D Training - Unleashing 3D Power on a 2D Budget</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/pf-score/">Implementation of Probabilistic FScore</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/gcvit/">Global Context Vision Transformer (GCViT)</a> </li> <div id="giscus_thread" style="max-width: 1100px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"alshedivat/al-folio","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"Comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Md Awsafur Rahman. Adopted from <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-DN6BSW1N8X"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-DN6BSW1N8X");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>